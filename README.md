# Configurador de Usuario y Verificador de WhatsApp con Chat Llama 3

Este proyecto proporciona una interfaz web simple con dos funcionalidades principales:
1.  **Configurador de Usuario**: Permite configurar datos de usuario y verificar una conexi칩n con la API de WhatsApp de Twilio enviando un mensaje de prueba.
2.  **Chat con Llama 3**: Ofrece una interfaz de chat para interactuar con el modelo de lenguaje Llama 3, que se ejecuta localmente a trav칠s de Ollama.

La aplicaci칩n est치 completamente contenedorizada con Docker, lo que garantiza una instalaci칩n y ejecuci칩n sencillas.

---

## 游 C칩mo Funciona

La aplicaci칩n utiliza Streamlit para crear la interfaz web. Al rellenar y enviar el formulario de configuraci칩n, la aplicaci칩n usa las credenciales de Twilio para enviar un mensaje de prueba.

Paralelamente, la aplicaci칩n incluye una secci칩n de chat que se conecta a un servicio de Ollama que se ejecuta en un contenedor Docker separado. Esto te permite chatear con el modelo Llama 3 directamente desde la interfaz.

---

## 丘뙖잺 Configuraci칩n Manual: Credenciales de Twilio

Para que la aplicaci칩n pueda enviar mensajes a trav칠s de WhatsApp, es **esencial** que configures tus credenciales de Twilio. Sigue estos pasos:

### Paso 1: Ve a la carpeta ra칤z de tu proyecto

Abre una terminal y aseg칰rate de estar en el directorio principal del proyecto (la misma carpeta donde se encuentra el archivo `docker-compose.yml`).

### Paso 2: Crea el directorio `.streamlit`

Si este directorio no existe, cr칠alo con el siguiente comando. Si ya existe, puedes omitir este paso.

```bash
mkdir .streamlit
```

### Paso 3: Crea tu archivo de secretos

Crea el archivo que guardar치 tus credenciales. Puedes usar la plantilla que he incluido en el repositorio para que sea m치s f치cil:

```bash
cp .streamlit/secrets.toml.template .streamlit/secrets.toml
```

### Paso 4: A침ade tus credenciales al archivo

Abre el archivo `.streamlit/secrets.toml` con tu editor de c칩digo favorito y ver치s el siguiente contenido:

```toml
# Credenciales de Twilio
# Reemplaza los valores con tus credenciales reales de la consola de Twilio.

# Tu Account SID de Twilio.
TWILIO_ACCOUNT_SID = "ACxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

# Tu Auth Token de Twilio.
TWILIO_AUTH_TOKEN = "tu_auth_token_aqui"

# Tu n칰mero de tel칠fono de Twilio con capacidad para WhatsApp.
# Debe tener el formato: whatsapp:+CODIGO_PAISNUMERO
TWILIO_PHONE_NUMBER = "whatsapp:+15017122661"
```

### Paso 5: Rellena con tus credenciales reales

Reemplaza los valores de ejemplo con tus credenciales, que puedes encontrar en [la consola de Twilio](https://www.twilio.com/console).

*   **`ACxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`**: Reempl치zalo con tu **Account SID**.
*   **`tu_auth_token_aqui`**: Reempl치zalo con tu **Auth Token**.
*   **`whatsapp:+15017122661`**: Reempl치zalo con tu **n칰mero de tel칠fono de Twilio para WhatsApp**.

> **丘멆잺 Importante sobre el Sandbox de Twilio**: Si usas el sandbox, aseg칰rate de haber vinculado tu n칰mero de WhatsApp personal al sandbox enviando el mensaje de activaci칩n (por ejemplo, `join company-slug`) desde tu WhatsApp al n칰mero del sandbox.

### Paso 6: Guarda y reinicia la aplicaci칩n

Una vez que hayas guardado el archivo con tus secretos, reinicia la aplicaci칩n para que se apliquen los cambios.

```bash
docker-compose up --build
```

El archivo `.gitignore` del proyecto ya est치 configurado para **ignorar** el archivo `secrets.toml`, por lo que tus credenciales permanecer치n seguras en tu m치quina local y no se subir치n al repositorio.

---

## 郊윒잺 Ejecuci칩n con Docker (Recomendado)

La forma m치s sencilla de ejecutar todo el sistema, incluido el chat con Llama 3.

### Prerrequisitos

*   **Docker y Docker Compose**: La forma m치s f치cil es usar [Docker Desktop](https://www.docker.com/products/docker-desktop/).
*   **Git**: Para clonar el repositorio.

### Pasos

1.  **Clona el repositorio** (si no lo has hecho ya):
    ```bash
    git clone https://github.com/jdmmit/Agente_Asistente.git
    cd Agente_Asistente
    ```

2.  **Levanta la aplicaci칩n y el servicio de Ollama**:
    ```bash
    docker compose up --build
    ```

3.  **Descarga el modelo Llama 3 (en una nueva terminal)**:
    Mientras los contenedores se ejecutan, abre una nueva terminal y ejecuta el siguiente comando para que el servicio de Ollama descargue el modelo Llama 3.
    ```bash
    docker exec -it ollama_service ollama pull llama3
    ```
    > **Nota**: Este paso solo es necesario la primera vez. El modelo se guardar치 en un volumen de Docker y estar치 disponible en futuros inicios.

4.  **Accede a la Interfaz**:
    Abre tu navegador y dir칤gete a `http://localhost:8501`.

---

## 郊윒잺 Ejecuci칩n en Local (Sin Docker)

Si prefieres no usar Docker, puedes ejecutar la aplicaci칩n de Streamlit directamente. **Nota**: Este m칠todo no incluye la ejecuci칩n del modelo Llama 3, ya que requiere una instalaci칩n local de Ollama.

### Prerrequisitos

*   **Python 3.8+** y **pip**.
*   **Git**.

### Pasos

1.  **Clona el repositorio** y entra en el directorio.

2.  **Crea y activa un entorno virtual**:
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    ```

3.  **Instala las dependencias**:
    ```bash
    pip install -r requirements.txt
    ```

4.  **Ejecuta la aplicaci칩n**:
    ```bash
    streamlit run streamlit_app.py
    ```

5.  **Accede a la Interfaz**:
    Abre tu navegador y dir칤gete a la URL que te indique la terminal.

---

## 游닇 Uso de la Aplicaci칩n

*   **Para verificar WhatsApp**: Rellena el formulario y haz clic en "Guardar y Enviar Mensaje de Prueba".
*   **Para chatear con Llama 3**: Despl치zate hacia abajo hasta la secci칩n de chat, escribe tu pregunta y presiona Enter.
